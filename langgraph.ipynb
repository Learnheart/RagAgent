{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pprint import pprint\n",
    "import os\n",
    "import time\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & call llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linhbk/Documents/python projects/NCKH_2024/RagAgent/agent_libs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_model = FastEmbedEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    cache_dir=\"./embedding_cache\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "llm = ChatGroq(model_name='Llama3-8b-8192', api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Chunking text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/vectorstore.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_with_metadata = json.load(f)\n",
    "\n",
    "doc_splits = [\n",
    "    Document(\n",
    "        page_content=chunk[\"text\"],\n",
    "        metadata={\n",
    "            \"chapter\": chunk[\"metadata\"][\"chapter\"],\n",
    "            \"title\": chunk[\"metadata\"][\"title\"],\n",
    "            \"date\": chunk[\"metadata\"][\"date\"]\n",
    "        }\n",
    "    ) for chunk in chunks_with_metadata\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2607"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_count = len(doc_splits)\n",
    "doc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save vector db in persist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist_directory = './real_estate_db/luat_dat_dai'\n",
    "persist_directory = './real_estate_db/vectorstore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create db\n",
    "# vectorstore_created = Chroma.from_documents(documents=doc_splits,\n",
    "#                                     embedding=embed_model,\n",
    "#                                     persist_directory=persist_directory,\n",
    "#                                     collection_name=\"vectorstore\")\n",
    "# vectorstore_created.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/64gffy7j1_79tlsdxkhtcjg00000gp/T/ipykernel_8717/1442968809.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embed_model, collection_name=\"vectorstore\")\n"
     ]
    }
   ],
   "source": [
    "# call from existed db\n",
    "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embed_model, collection_name=\"vectorstore\")\n",
    "# vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stored documents: 2607\n",
      "Files in persistence directory: ['1aead4fb-bcb3-496d-86d1-dda9b04741f6', 'chroma.sqlite3']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stored documents:\", vectorstore._collection.count())\n",
    "# print(\"First document:\", doc_splits[-1].page_content if doc_splits else \"No documents found!\")\n",
    "print(\"Files in persistence directory:\", os.listdir(persist_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: ['vectorstore']\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "client = PersistentClient(path=persist_directory)\n",
    "collections = client.list_collections()\n",
    "print(\"Available collections:\", collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_lambda = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# # convert chunks to document\n",
    "# def format_text_chunks(text_chunks):\n",
    "#     return [Document(page_content=chunk) for chunk in text_chunks]\n",
    "\n",
    "# retriever_lambda = RunnableLambda(lambda x: format_text_chunks(retriever.get_relevant_documents(x[\"question\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "filter_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI-based information filter responsible for categorizing user input questions.\n",
    "    Your mission is to return a binary choice \"yes\" or \"no\" indicating whether the question is related to sensitive topics.\n",
    "    Sensitive topics include hate-speech, sexuality, politics, historical, violence, religion.\n",
    "    \n",
    "    **IMPORTANT**: Your response **MUST** be a valid JSON object with a single key \"score\" and a value of \"yes\" or \"no\". \n",
    "    **NOTE**: If topic is related to vietnamese laws, its not the sensitive topic even refer to senstive topics. \n",
    "    **DO NOT** include any other text or explanation.\n",
    "    \n",
    "    For example: \n",
    "    Input: \"ai là người lãnh đạo đảng?\"\n",
    "    Output: {{\"score\": \"yes\"}}\n",
    "\n",
    "    Input: \"việt tân là ai?\"\n",
    "    Output: {{\"score\": \"yes\"}}\n",
    "    \n",
    "    Input: \"luật việt nam là như nào?\"\n",
    "    Output: {{\"score\": \"no\"}}\n",
    "    \n",
    "    Input: \"tội hiếp dâm và giết người bị phán bao nhiêu năm tù?\"\n",
    "    Output: {{\"score\": \"no\"}}\n",
    "    \n",
    "    Question need to filtered: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "filter_chain = (filter_prompt | llm | JsonOutputParser())\n",
    "\n",
    "# test\n",
    "question = \"“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\"\n",
    "filter_result = filter_chain.invoke({\"question\": question})\n",
    "print(filter_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'vectorstore'}\n",
      "The time required to generate response by Router Chain in seconds:0.2564280033111572\n"
     ]
    }
   ],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on real estate laws in Vietnam. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "question_router = router_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by Router Chain in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/64gffy7j1_79tlsdxkhtcjg00000gp/T/ipykernel_8717/2309398310.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever_lambda = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theo quy định của Luật Đất đai năm 2024, \"người sử dụng đất\" được hiểu là các cá nhân, tổ chức, hộ gia đình, cộng đồng dân cư, người Việt Nam trong nước, người nước ngoài, doanh nghiệp có vốn đầu tư nước ngoài, các tổ chức phi chính phủ, các tổ chức quốc tế... có quyền sử dụng đất đai thuộc lãnh thổ của nước Cộng hòa xã hội chủ nghĩa Việt Nam.\n",
      "\n",
      "Theo Điều 3 của Luật Đất đai năm 2024, người sử dụng đất bao gồm:\n",
      "\n",
      "* Cá nhân, hộ gia đình, tổ chức, cộng đồng dân cư có quyền sử dụng đất;\n",
      "* Doanh nghiệp có vốn đầu tư nước ngoài, các tổ chức phi chính phủ, các tổ chức quốc tế được phép hoạt động tại Việt Nam;\n",
      "* Các đối tượng khác được Nhà nước giao quyền sử dụng đất.\n",
      "\n",
      "Theo Điều 40 của Nghị định số 96/2024/NĐ-CP, người sử dụng đất là các cá nhân, tổ chức, hộ gia đình, cộng đồng dân cư, người Việt Nam trong nước, người nước ngoài, doanh nghiệp có vốn đầu tư nước ngoài, các tổ chức phi chính phủ, các tổ chức quốc tế... có quyền sử dụng đất đai.\n",
      "\n",
      "Trong đó, người sử dụng đất phải tuân thủ các quy định của pháp luật về đất đai, bao gồm các quy định về quyền và nghĩa vụ của người sử dụng đất, các quy định về hạn chế quyền sử dụng đất, các quy định về thuế và phí liên quan đến đất đai, các quy định về quản lý và sử dụng đất đai.\n",
      "\n",
      "REFERENCE:\n",
      "\n",
      "* Luật Đất đai năm 2024, Điều 3\n",
      "* Nghị định số 96/2024/NĐ-CP, Điều 40\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just refuse answer in polite and friendly. \n",
    "    Answer question in detailed, make sure references vietnamese's law that prove for your answer. \n",
    "    For example:\n",
    "    Question: Phạm vi điều chỉnh và đối tượng áp dụng Luật Đất đai năm 2024 là gì?\n",
    "    Answer: \n",
    "    Điều 1. Phạm vi điều chỉnh\n",
    "    Luật này quy định về chế độ sở hữu đất đai, quyền hạn và trách nhiệm của Nhà nước đại diện chủ sở hữu toàn dân về đất đai và thống nhất quản lý về đất đai, chế độ quản lý và sử dụng đất đai, quyền và nghĩa vụ của công dân, người sử dụng đất đối với đất đai thuộc lãnh thổ của nước Cộng hòa xã hội chủ nghĩa Việt Nam.\n",
    "    Điều 2. Đối tượng áp dụng\n",
    "    1. Cơ quan nhà nước thực hiện quyền hạn và trách nhiệm đại diện chủ sở hữu toàn dân về đất đai, thực hiện nhiệm vụ thống nhất quản lý nhà nước về đất đai.\n",
    "    2. Người sử dụng đất.\n",
    "    3. Các đối tượng khác có liên quan đến việc quản lý, sử dụng đất đai.'\n",
    "    Answer in professional in vietnamese.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "start = time.time()\n",
    "rag_chain = (\n",
    "    {\"question\": lambda x: x[\"question\"], \"context\": retriever_lambda}\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# test\n",
    "# question = \"luật nhà ở 2024\"\n",
    "response = rag_chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 1 content: Điều 28.Nhận quyền sử dụng đất\n",
      "1\n",
      "retriever 1 grade: {'score': 'no'}\n",
      "doc 2 content: - Những hạn chế về quyền sử dụng đất (nếu có): ..........................................................\n",
      "2\n",
      "retriever 2 grade: {'score': 'no'}\n",
      "doc 3 content: quyền sử dụng đất thì không cần mô tả thông tin này)\n",
      "- Tiến độ thực hiện: .....................................................................................................\n",
      "- Các nội dung khác: ...................................................................................................\n",
      "điều 2\n",
      "retriever 3 grade: {'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "retrieval_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. \\n\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "start = time.time()\n",
    "retrieval_grader = retrieval_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "docs = retriever.invoke(question)\n",
    "end = time.time()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    doc_txt = doc.page_content\n",
    "    print(f\"doc {i + 1} content: {doc_txt}\")\n",
    "    doc_grader = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "    print(f\"retriever {i + 1} grade: {doc_grader}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the generation chain in seconds:0.3961951732635498\n",
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "hallucination_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "start = time.time()\n",
    "hallucination_grader = hallucination_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "hallucination_grader_response = hallucination_grader.invoke({\"documents\": docs, \"generation\": response})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the generation chain in seconds:{end - start}\")\n",
    "print(hallucination_grader_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANswer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the answer grader in seconds:0.2849690914154053\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "answer_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "answer_grader = answer_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "answer_grader_response = answer_grader.invoke({\"question\": question,\"generation\": response})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the answer grader in seconds:{end - start}\")\n",
    "print(answer_grader_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Websearch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.environ['TAVILY_API_KEY']\n",
    "web_search_tool = TavilySearchResults(k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single test web_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Thị trường bất động sản cuối năm 2024: Kỳ vọng bứt phá', 'url': 'https://consosukien.vn/thi-truong-bat-dong-san-cuoi-nam-2024-ky-vong-but-pha.htm', 'content': 'Cụ thể, mức độ quan tâm đất trong Quý III/2024 dự kiến tăng 49% so với cùng kỳ năm 2023, nhà riêng tăng 25%, chung cư tăng 24%, biệt thự tăng 22', 'score': 0.77364457}, {'title': 'Nhìn lại thị trường bất động sản năm 2024 - Báo Kinh tế đô thị', 'url': 'https://kinhtedothi.vn/nhin-lai-thi-truong-bat-dong-san-nam-2024.html', 'content': 'Tính chung cả năm 2024, toàn thị trường ghi nhận khoảng gần 81.000 sản phẩm chào bán, tăng hơn 40% so với năm 2023. Trong đó, có 65,376 sản phẩ', 'score': 0.694798776}, {'title': 'Toàn cảnh thị trường bất động sản 2024 - VTV.vn', 'url': 'https://vtv.vn/kinh-te/toan-canh-thi-truong-bat-dong-san-2024-20241223201533067.htm', 'content': 'Năm 2024 đang khép lại, thị trường bất động sản đã có một năm chuyển biến đầy tích cực. Các phân khúc bất động sản đã có những diễn biến hồi', 'score': 0.6066514000000001}, {'title': 'Diễn biến nổi bật thị trường bất động sản năm 2024', 'url': 'https://baotainguyenmoitruong.vn/dien-bien-noi-bat-thi-truong-bat-dong-san-nam-2024-385181.html', 'content': '(TN&MT) - Năm 2024 thị trường bất động sản Việt Nam chứng kiến nhiều chuyển biến quan trọng với sự ra đời của những khuôn khổ pháp lý mới rõ', 'score': 0.5188183}, {'title': 'Năm 2024, nguồn cung bất động sản tăng trưởng mạnh', 'url': 'https://baochinhphu.vn/nam-2024-nguon-cung-bat-dong-san-tang-truong-manh-10224123109473222.htm', 'content': 'Tại thời điểm cuối năm 2024, thị trường BĐS ghi nhận khoảng 56 nghìn sản phẩm chào bán trên thị trường sơ cấp, tương đương với thời điểm cuối', 'score': 0.442669524}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.tools import TavilySearchResults\n",
    "\n",
    "def search_web(query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Searches the web using Tavily API for the given query.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The search query.\n",
    "    - k (int): Number of search results to return (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of search result snippets.\n",
    "    \"\"\"\n",
    "    tavily_api_key = os.environ['TAVILY_API_KEY']\n",
    "    web_search_tool = TavilySearchResults(k=k)\n",
    "    \n",
    "    try:\n",
    "        results = web_search_tool.run(query)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error while searching: {e}\")\n",
    "        return []\n",
    "\n",
    "query = \"TÌnh hình bất đọngo sản 2024\"\n",
    "search_results = search_web(query)\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraphh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str]\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_question(state):\n",
    "    question = state[\"question\"]\n",
    "    return {\"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    try:\n",
    "        documents = retriever.invoke(question)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieval: {e}\")\n",
    "        documents = []\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "#\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    iterations = state.get(\"iterations\", 0) + 1\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation, \"iterations\": iterations}\n",
    "#\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "#\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    iterations = state.get(\"iterations\", 0) + 1\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.run({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question, \"iterations\": iterations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_question(state):\n",
    "    \"\"\"\n",
    "    Filter the question for sensitive topics\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    \n",
    "    Returns:\n",
    "        dict: Updated state with decision to end or continue\n",
    "    \"\"\"\n",
    "    print(\"---FILTER QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    filter_result = filter_chain.invoke({\"question\": question})\n",
    "    if filter_result[\"score\"] == \"yes\":\n",
    "        print(\"---SENSITIVE TOPIC DETECTED---\")\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        print(\"---QUESTION PASSED FILTER---\")\n",
    "        return \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    iterations = state.get(\"iterations\", 0)\n",
    "    print(f\"number of iteration at this hallucination term: {iterations}\")\n",
    "    \n",
    "    if iterations >= 10:\n",
    "        print(\"GETTING MAX ATTEMPTS\")\n",
    "        return \"end\"\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x307395610>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"route_question\", route_question)\n",
    "workflow.add_node(\"parse_question\", parse_question)\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generatae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry & End points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x307395610>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    filter_question,\n",
    "    {\n",
    "        \"yes\": END,\n",
    "        \"no\": \"parse_question\"\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"parse_question\",\n",
    "    route_question,     \n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "        \"end\": END\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FILTER QUESTION---\n",
      "---QUESTION PASSED FILTER---\n",
      "---ROUTE QUESTION---\n",
      "what is my name?\n",
      "{'datasource': 'web_search'}\n",
      "web_search\n",
      "---ROUTE QUESTION TO WEB SEARCH---\n",
      "'Finished running: parse_question:'\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 2\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely decline to answer your question \"\n",
      " 'as the context provided does not contain any information about your name. '\n",
      " 'The context appears to be related to Vietnamese laws, specifically documents '\n",
      " 'related to business, housing, and land, but it does not mention your name. '\n",
      " \"If you could provide more context or clarify your question, I'll do my best \"\n",
      " 'to assist you.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 3\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have any information about your name in the \"\n",
      " 'provided context. The documents you provided are about laws related to '\n",
      " 'business, real estate, and land, but they do not contain any information '\n",
      " \"about a person's name.\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 4\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely decline to answer your question \"\n",
      " \"because I don't have any information about your name in the provided \"\n",
      " 'context. The context only includes metadata and page content from three '\n",
      " 'documents related to Vietnamese laws, but none of them mention your name. If '\n",
      " \"you could provide more information or context about your name, I'd be happy \"\n",
      " 'to try and help you with your question!')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 5\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely refuse to answer your question \"\n",
      " 'as it is not related to the provided context, which appears to be excerpts '\n",
      " 'from Vietnamese laws. The context does not contain any information about a '\n",
      " \"person's name, including yours.\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 6\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely decline to answer the question \"\n",
      " '\"What is my name?\" as I am an AI assistant and do not have a personal name. '\n",
      " 'I exist solely to provide information and assist with tasks to the best of '\n",
      " 'my abilities.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 7\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "('I apologize, but the context provided does not contain any information about '\n",
      " 'your name. The context consists of metadata and page content from three '\n",
      " 'different legal documents, including the Law on Business Activities of Real '\n",
      " 'Estate, the Law on Housing, and the Law on Land. There is no mention of a '\n",
      " 'name in this context.\\n'\n",
      " '\\n'\n",
      " 'As a respectful and polite assistant, I must decline to provide an answer to '\n",
      " 'this question since it is not relevant to the provided context. If you could '\n",
      " \"provide more information or clarify what you are looking for, I'd be happy \"\n",
      " 'to assist you to the best of my abilities.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 8\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have any information about your name in the \"\n",
      " 'provided context. The context only includes metadata and page content from '\n",
      " 'three different documents related to Vietnamese laws, but it does not '\n",
      " 'contain any personal information or details about a specific individual, '\n",
      " 'including your name.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 9\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have the necessary information to answer your \"\n",
      " \"question. The provided context doesn't contain any information about your \"\n",
      " 'name. It appears to be a collection of documents related to Vietnamese laws, '\n",
      " 'but there is no personal information present. \\n'\n",
      " '\\n'\n",
      " \"As a professional assistant, I must be honest and transparent. I don't have \"\n",
      " 'the capability to access or provide personal information, including names. '\n",
      " 'If you have any other questions related to Vietnamese laws or any other '\n",
      " \"topics, I'll do my best to assist you.\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 10\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have any information about your name in the \"\n",
      " 'provided context. The context only includes documents related to Vietnamese '\n",
      " \"laws, and there is no mention of a name. I'm happy to help with any \"\n",
      " 'questions about the laws or regulations mentioned in the context, but I '\n",
      " \"wouldn't be able to provide your name as it's not mentioned.\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 11\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help you with your question! However, I must politely point out \"\n",
      " 'that the context provided does not contain any information about your name. '\n",
      " 'The documents you shared appear to be related to Vietnamese laws, '\n",
      " 'specifically the Law on Business of Immovable Property, the Law on Housing, '\n",
      " 'and the Law on Land, but they do not mention your name.\\n'\n",
      " '\\n'\n",
      " 'As a responsible AI assistant, I must refuse to answer questions that '\n",
      " 'require personal information or details that are not provided. If you meant '\n",
      " \"to ask a different question or provide more context, I'd be happy to help. \"\n",
      " 'Please feel free to ask again!')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 12\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have the information about your name in the \"\n",
      " 'provided context. The context seems to be related to Vietnamese laws, '\n",
      " \"specifically the laws about business, real estate, and land, but it doesn't \"\n",
      " \"contain any personal information about you, including your name. I'm an \"\n",
      " \"assistant, I don't have access to personal information, and I'm not designed \"\n",
      " 'to provide information about individuals. I can only provide information '\n",
      " \"based on the context provided, and in this case, the context doesn't contain \"\n",
      " 'your name.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 13\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely refuse to answer your question \"\n",
      " 'as it is not related to the provided context, which appears to be Vietnamese '\n",
      " 'laws and articles. The context does not contain any information about your '\n",
      " 'name.\\n'\n",
      " '\\n'\n",
      " \"If you meant to ask a question related to the provided context, I'll do my \"\n",
      " 'best to answer it accurately and provide references to the relevant '\n",
      " \"Vietnamese laws. Please rephrase your question, and I'll be happy to help!\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 14\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "('I cannot provide information about your name. Is there anything else I can '\n",
      " 'help you with?')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 15\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "('I apologize, but the context provided does not contain any information about '\n",
      " 'your name. The context appears to be related to Vietnamese laws, '\n",
      " 'specifically documents on laws regarding business, real estate, and land. '\n",
      " \"There is no personal information or data about an individual's name.\\n\"\n",
      " '\\n'\n",
      " 'I cannot provide an answer to your question as it is not related to the '\n",
      " 'provided context. If you meant to ask a different question or provide '\n",
      " \"additional context, I'll be happy to assist you.\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 16\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely refuse to answer this question \"\n",
      " 'as it is not related to the provided context or Vietnamese laws. The context '\n",
      " 'you provided consists of three documents related to different laws (Luật '\n",
      " 'Kinh Doanh Bất Động Sản, Luật Nhà Ở, and Luật Đất Đai) with articles and '\n",
      " 'chapters, but none of them contain information about your name.\\n'\n",
      " '\\n'\n",
      " 'As a question-answering assistant, I can only provide information based on '\n",
      " 'the provided context and Vietnamese laws. If you have any questions or '\n",
      " \"concerns about the laws or regulations, I'll do my best to help you with \"\n",
      " 'that!')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 17\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have any information about your name in the \"\n",
      " 'provided context. The context includes documents related to laws such as the '\n",
      " 'Law on Business of Real Estate, Law on Residence, and Law on Land, but none '\n",
      " 'of these documents contain any information about your name. Therefore, I '\n",
      " 'cannot answer this question.\\n'\n",
      " '\\n'\n",
      " \"If you could provide more context or information about your name, I'll be \"\n",
      " 'happy to help you with your question.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 18\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely point out that the context you \"\n",
      " 'provided does not contain any information about your name. The documents you '\n",
      " 'shared appear to be related to Vietnamese laws, such as the Law on Business '\n",
      " 'of Real Estate, the Law on Housing, and the Law on Land. They do not mention '\n",
      " 'your name or any personal information.\\n'\n",
      " '\\n'\n",
      " 'As a result, I cannot provide an answer to your question about your name. If '\n",
      " 'you could provide more context or clarify what you are looking for, I would '\n",
      " 'be happy to try and assist you.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 19\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely decline to answer the question \"\n",
      " '\"What is my name?\" as I am an AI assistant and do not have a personal name. '\n",
      " \"I'm here to assist with providing detailed answers to your questions based \"\n",
      " \"on the provided context, but I don't have personal information or identity.\\n\"\n",
      " '\\n'\n",
      " \"If you have any other questions or topics you'd like to discuss, I'm here to \"\n",
      " 'help!')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 20\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must point out that there is no information \"\n",
      " 'about your name in the provided context. The context appears to be a '\n",
      " 'collection of legal documents, and none of them mention your name.\\n'\n",
      " '\\n'\n",
      " 'As a polite and friendly assistant, I would like to respectfully inform you '\n",
      " 'that I do not have the capability to access or provide information about '\n",
      " 'your personal details, including your name. I can only provide information '\n",
      " 'based on the context provided, and in this case, there is no information '\n",
      " 'about your name.\\n'\n",
      " '\\n'\n",
      " 'If you have any other questions or concerns, please feel free to ask, and '\n",
      " \"I'll do my best to assist you!\")\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 21\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have the information about your name. The provided \"\n",
      " 'context is related to Vietnamese laws and does not contain any information '\n",
      " \"about your name. I'm not a personal assistant, and I don't have access to \"\n",
      " 'personal information. Can I help you with something else?')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 22\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "('Em không tìm thấy thông tin về tên của bạn trong văn bản pháp lý được cung '\n",
      " 'cấp. Vì vậy, em không thể trả lời được câu hỏi về tên của bạn. Em không thể '\n",
      " 'cung cấp thông tin không có căn cứ về một vấn đề riêng tư như tên của người '\n",
      " 'dùng. Em chỉ có thể trả lời các câu hỏi dựa trên các văn bản pháp lý được '\n",
      " 'cung cấp và các quy định của pháp luật Việt Nam.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 23\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I'm happy to help! However, I must politely refuse to answer your question \"\n",
      " 'because the context you provided does not contain any information about your '\n",
      " 'name. The documents appear to be related to Vietnamese laws, but they do not '\n",
      " 'mention your name.\\n'\n",
      " '\\n'\n",
      " \"If you're looking for information about yourself, I suggest checking your \"\n",
      " 'personal documents, such as your ID card, passport, or other identification '\n",
      " \"documents. If you're having trouble finding the answer, you may want to \"\n",
      " 'reach out to a trusted friend, family member, or authority figure who may be '\n",
      " \"able to provide you with the information you're looking for.\\n\"\n",
      " '\\n'\n",
      " 'Remember, as a responsible and professional assistant, I am here to provide '\n",
      " \"accurate and helpful information to the best of my abilities. If I don't \"\n",
      " 'know the answer to a question, I will always let you know and suggest '\n",
      " 'alternative resources that may be able to provide the information you need.')\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "number of iteration at this hallucination term: 24\n",
      "'---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---'\n",
      "'Finished running: generate:'\n",
      "(\"I apologize, but I don't have enough information to answer your question. \"\n",
      " 'The provided context does not contain any information about your name.')\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwhat is my name?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFinished running: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/python projects/NCKH_2024/RagAgent/agent_libs/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2044\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2035\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2036\u001b[39m     msg = create_error_message(\n\u001b[32m   2037\u001b[39m         message=(\n\u001b[32m   2038\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2042\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2043\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2045\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2046\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"what is my name?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "\n",
    "        if key == \"filter_question\" and value == \"yes\":\n",
    "            pprint(\"xin loi toi khong the tra loi cau hoi nay\")\n",
    "            break\n",
    "\n",
    "    if \"generation\" in value:\n",
    "        pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_libs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
