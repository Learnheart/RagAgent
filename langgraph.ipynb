{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pprint import pprint\n",
    "import os\n",
    "import time\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & call llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linhbk/Documents/python projects/NCKH_2024/RagAgent/agent_libs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_model = FastEmbedEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    cache_dir=\"./embedding_cache\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "llm = ChatGroq(model_name='Llama3-8b-8192', api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Chunking text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/vectorstore.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_with_metadata = json.load(f)\n",
    "\n",
    "doc_splits = [\n",
    "    Document(\n",
    "        page_content=chunk[\"text\"],\n",
    "        metadata={\n",
    "            \"chapter\": chunk[\"metadata\"][\"chapter\"],\n",
    "            \"title\": chunk[\"metadata\"][\"title\"],\n",
    "            \"date\": chunk[\"metadata\"][\"date\"]\n",
    "        }\n",
    "    ) for chunk in chunks_with_metadata\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2607"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_count = len(doc_splits)\n",
    "doc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save vector db in persist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist_directory = './real_estate_db/luat_dat_dai'\n",
    "persist_directory = './real_estate_db/vectorstore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create db\n",
    "# vectorstore_created = Chroma.from_documents(documents=doc_splits,\n",
    "#                                     embedding=embed_model,\n",
    "#                                     persist_directory=persist_directory,\n",
    "#                                     collection_name=\"vectorstore\")\n",
    "# vectorstore_created.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/64gffy7j1_79tlsdxkhtcjg00000gp/T/ipykernel_8583/1442968809.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embed_model, collection_name=\"vectorstore\")\n"
     ]
    }
   ],
   "source": [
    "# call from existed db\n",
    "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embed_model, collection_name=\"vectorstore\")\n",
    "# vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stored documents: 2607\n",
      "Files in persistence directory: ['1aead4fb-bcb3-496d-86d1-dda9b04741f6', 'chroma.sqlite3']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stored documents:\", vectorstore._collection.count())\n",
    "# print(\"First document:\", doc_splits[-1].page_content if doc_splits else \"No documents found!\")\n",
    "print(\"Files in persistence directory:\", os.listdir(persist_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: ['vectorstore']\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "client = PersistentClient(path=persist_directory)\n",
    "collections = client.list_collections()\n",
    "print(\"Available collections:\", collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_lambda = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# # convert chunks to document\n",
    "# def format_text_chunks(text_chunks):\n",
    "#     return [Document(page_content=chunk) for chunk in text_chunks]\n",
    "\n",
    "# retriever_lambda = RunnableLambda(lambda x: format_text_chunks(retriever.get_relevant_documents(x[\"question\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "filter_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI-based information filter responsible for categorizing user input questions.\n",
    "    Your mission is to return a binary choice \"yes\" or \"no\" indicating whether the question is related to sensitive topics.\n",
    "    Sensitive topics include hate-speech, sexuality, politics, historical, violence, religion.\n",
    "    \n",
    "    **IMPORTANT**: Your response **MUST** be a valid JSON object with a single key \"score\" and a value of \"yes\" or \"no\". \n",
    "    **NOTE**: If topic is related to vietnamese laws, its not the sensitive topic even refer to senstive topics. \n",
    "    **DO NOT** include any other text or explanation.\n",
    "    \n",
    "    For example: \n",
    "    Input: \"ai là người lãnh đạo đảng?\"\n",
    "    Output: {{\"score\": \"yes\"}}\n",
    "\n",
    "    Input: \"việt tân là ai?\"\n",
    "    Output: {{\"score\": \"yes\"}}\n",
    "    \n",
    "    Input: \"luật việt nam là như nào?\"\n",
    "    Output: {{\"score\": \"no\"}}\n",
    "    \n",
    "    Input: \"tội hiếp dâm và giết người bị phán bao nhiêu năm tù?\"\n",
    "    Output: {{\"score\": \"no\"}}\n",
    "    \n",
    "    Question need to filtered: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "filter_chain = (filter_prompt | llm | JsonOutputParser())\n",
    "\n",
    "# test\n",
    "question = \"“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\"\n",
    "filter_result = filter_chain.invoke({\"question\": question})\n",
    "print(filter_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'vectorstore'}\n",
      "The time required to generate response by Router Chain in seconds:0.24796390533447266\n"
     ]
    }
   ],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on real estate laws in Vietnam. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "question_router = router_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by Router Chain in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/64gffy7j1_79tlsdxkhtcjg00000gp/T/ipykernel_8583/2309398310.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever_lambda = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theo quy định của Luật Đất đai năm 2024, \"người sử dụng đất\" được hiểu là các đối tượng có quyền sử dụng đất, bao gồm:\n",
      "\n",
      "* Những người có quyền sử dụng đất được Nhà nước giao, cho, bán, tặng, thừa kế hoặc khác;\n",
      "* Các tổ chức, cá nhân có quyền sử dụng đất được phép thực hiện các hoạt động kinh doanh, sản xuất, dịch vụ, nghiên cứu, giáo dục, nghỉ ngơi, giải trí và các mục đích khác trên đất đai;\n",
      "\n",
      "Điều 3, Luật Đất đai năm 2024 quy định: \"Người sử dụng đất bao gồm:\n",
      "\n",
      "* Cá nhân;\n",
      "* Tổ chức;\n",
      "* Doanh nghiệp;\n",
      "* Hợp tác xã;\n",
      "* Cộng đồng dân cư;\n",
      "* Các tổ chức tín dụng;\n",
      "* Các tổ chức khác có quyền sử dụng đất.\"\n",
      "\n",
      "Theo Điều 4, Luật Đất đai năm 2024, người sử dụng đất phải thực hiện các nghĩa vụ sau:\n",
      "\n",
      "* Phải sử dụng đất đúng mục đích và theo quy hoạch đã được phê duyệt;\n",
      "* Phải nộp thuế và các khoản thu khác về đất đai theo quy định của pháp luật;\n",
      "* Phải bảo vệ và bảo tồn đất đai, phòng chống và ngăn chặn các hiện tượng thiên tai, cháy rừng, lũ lụt, sạt lở, ô nhiễm môi trường và các hiện tượng khác;\n",
      "* Phải tuân thủ các quy định của pháp luật về quản lý và sử dụng đất đai.\n",
      "\n",
      "Tóm lại, người sử dụng đất là những người có quyền sử dụng đất và phải thực hiện các nghĩa vụ và trách nhiệm được quy định trong Luật Đất đai năm 2024.\n",
      "\n",
      "Nguồn: Luật Đất đai năm 2024, Điều 3, Điều 4.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just refuse answer in polite and friendly. \n",
    "    Answer question in detailed, make sure references vietnamese's law that prove for your answer. \n",
    "    For example:\n",
    "    Question: Phạm vi điều chỉnh và đối tượng áp dụng Luật Đất đai năm 2024 là gì?\n",
    "    Answer: \n",
    "    Điều 1. Phạm vi điều chỉnh\n",
    "    Luật này quy định về chế độ sở hữu đất đai, quyền hạn và trách nhiệm của Nhà nước đại diện chủ sở hữu toàn dân về đất đai và thống nhất quản lý về đất đai, chế độ quản lý và sử dụng đất đai, quyền và nghĩa vụ của công dân, người sử dụng đất đối với đất đai thuộc lãnh thổ của nước Cộng hòa xã hội chủ nghĩa Việt Nam.\n",
    "    Điều 2. Đối tượng áp dụng\n",
    "    1. Cơ quan nhà nước thực hiện quyền hạn và trách nhiệm đại diện chủ sở hữu toàn dân về đất đai, thực hiện nhiệm vụ thống nhất quản lý nhà nước về đất đai.\n",
    "    2. Người sử dụng đất.\n",
    "    3. Các đối tượng khác có liên quan đến việc quản lý, sử dụng đất đai.'\n",
    "    Answer in professional in vietnamese.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "start = time.time()\n",
    "rag_chain = (\n",
    "    {\"question\": lambda x: x[\"question\"], \"context\": retriever_lambda}\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# test\n",
    "# question = \"luật nhà ở 2024\"\n",
    "response = rag_chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 1 content: Điều 28.Nhận quyền sử dụng đất\n",
      "1\n",
      "retriever 1 grade: {'score': 'yes'}\n",
      "doc 2 content: - Những hạn chế về quyền sử dụng đất (nếu có): ..........................................................\n",
      "2\n",
      "retriever 2 grade: {'score': 'no'}\n",
      "doc 3 content: quyền sử dụng đất thì không cần mô tả thông tin này)\n",
      "- Tiến độ thực hiện: .....................................................................................................\n",
      "- Các nội dung khác: ...................................................................................................\n",
      "điều 2\n",
      "retriever 3 grade: {'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "retrieval_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. \\n\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "start = time.time()\n",
    "retrieval_grader = retrieval_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "docs = retriever.invoke(question)\n",
    "end = time.time()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    doc_txt = doc.page_content\n",
    "    print(f\"doc {i + 1} content: {doc_txt}\")\n",
    "    doc_grader = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "    print(f\"retriever {i + 1} grade: {doc_grader}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the generation chain in seconds:0.3030860424041748\n",
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "hallucination_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "start = time.time()\n",
    "hallucination_grader = hallucination_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "hallucination_grader_response = hallucination_grader.invoke({\"documents\": docs, \"generation\": response})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the generation chain in seconds:{end - start}\")\n",
    "print(hallucination_grader_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANswer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the answer grader in seconds:0.30902981758117676\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "answer_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "answer_grader = answer_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "answer_grader_response = answer_grader.invoke({\"question\": question,\"generation\": response})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the answer grader in seconds:{end - start}\")\n",
    "print(answer_grader_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Websearch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.environ['TAVILY_API_KEY']\n",
    "web_search_tool = TavilySearchResults(k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single test web_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Toàn cảnh thị trường bất động sản 9 tháng đầu năm 2024', 'url': 'https://laodong.vn/bat-dong-san/toan-canh-thi-truong-bat-dong-san-9-thang-dau-nam-2024-1397317.ldo', 'content': 'Theo đó, mức độ quan tâm đất trong quý III/2024 dự kiến tăng 49% so với cùng kỳ 2023, nhà riêng tăng 25%, chung cư tăng 24%, biệt thự tăng 22%.', 'score': 0.79293}, {'title': 'Thị trường bất động sản cuối năm 2024: Kỳ vọng bứt phá', 'url': 'https://consosukien.vn/thi-truong-bat-dong-san-cuoi-nam-2024-ky-vong-but-pha.htm', 'content': 'Cụ thể, mức độ quan tâm đất trong Quý III/2024 dự kiến tăng 49% so với cùng kỳ năm 2023, nhà riêng tăng 25%, chung cư tăng 24%, biệt thự tăng 22', 'score': 0.696280113}, {'title': 'Nhìn lại thị trường bất động sản năm 2024 - Báo Kinh tế đô thị', 'url': 'https://kinhtedothi.vn/nhin-lai-thi-truong-bat-dong-san-nam-2024.html', 'content': 'Tính chung cả năm 2024, toàn thị trường ghi nhận khoảng gần 81.000 sản phẩm chào bán, tăng hơn 40% so với năm 2023. Trong đó, có 65,376 sản phẩ', 'score': 0.617598912}, {'title': 'Toàn cảnh thị trường bất động sản 2024 - VTV.vn', 'url': 'https://vtv.vn/kinh-te/toan-canh-thi-truong-bat-dong-san-2024-20241223201533067.htm', 'content': 'Năm 2024 đang khép lại, thị trường bất động sản đã có một năm chuyển biến đầy tích cực. Các phân khúc bất động sản đã có những diễn biến hồi', 'score': 0.5308199749999999}, {'title': 'Năm 2024, nguồn cung bất động sản tăng trưởng mạnh', 'url': 'https://baochinhphu.vn/nam-2024-nguon-cung-bat-dong-san-tang-truong-manh-10224123109473222.htm', 'content': 'Theo Hội Môi giới bất động sản Việt Nam (VARS),tính chung cả năm 2024, toàn thị trường ghi nhận khoảng gần 81 nghìn sản phẩm bất động sản', 'score': 0.44711693999999996}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.tools import TavilySearchResults\n",
    "\n",
    "def search_web(query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Searches the web using Tavily API for the given query.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The search query.\n",
    "    - k (int): Number of search results to return (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of search result snippets.\n",
    "    \"\"\"\n",
    "    tavily_api_key = os.environ['TAVILY_API_KEY']\n",
    "    web_search_tool = TavilySearchResults(k=k)\n",
    "    \n",
    "    try:\n",
    "        results = web_search_tool.run(query)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error while searching: {e}\")\n",
    "        return []\n",
    "\n",
    "query = \"TÌnh hình bất đọngo sản 2024\"\n",
    "search_results = search_web(query)\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraphh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str]\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_question(state):\n",
    "    question = state[\"question\"]\n",
    "    return {\"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    try:\n",
    "        documents = retriever.invoke(question)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieval: {e}\")\n",
    "        documents = []\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "#\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    iterations = state.get(\"iterations\", 0) + 1\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation, \"iterations\": iterations}\n",
    "#\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "#\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    iterations = state.get(\"iterations\", 0) + 1\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.run({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question, \"iterations\": iterations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_question(state):\n",
    "    \"\"\"\n",
    "    Filter the question for sensitive topics\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    \n",
    "    Returns:\n",
    "        dict: Updated state with decision to end or continue\n",
    "    \"\"\"\n",
    "    print(\"---FILTER QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    filter_result = filter_chain.invoke({\"question\": question})\n",
    "    if filter_result[\"score\"] == \"yes\":\n",
    "        print(\"---SENSITIVE TOPIC DETECTED---\")\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        print(\"---QUESTION PASSED FILTER---\")\n",
    "        return \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    iterations = state.get(\"iterations\", 0)\n",
    "    print(f\"number of iteration at this hallucination term: {iterations}\")\n",
    "    \n",
    "    if iterations >= 50:\n",
    "        print(\"GETTING MAX ATTEMPTS\")\n",
    "        return \"end\"\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17ab4a180>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"route_question\", route_question)\n",
    "workflow.add_node(\"parse_question\", parse_question)\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generatae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry & End points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17ab4a180>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    filter_question,\n",
    "    {\n",
    "        \"yes\": END,\n",
    "        \"no\": \"parse_question\"\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"parse_question\",\n",
    "    route_question,     \n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "        \"end\": END\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FILTER QUESTION---\n",
      "---QUESTION PASSED FILTER---\n",
      "“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024? has type: <class 'str'>\n",
      "---ROUTE QUESTION---\n",
      "“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "'Finished running: parse_question:'\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "2\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('Theo quy định của Luật Đất đai năm 2024, \"người sử dụng đất\" được hiểu là '\n",
      " 'các tổ chức, cá nhân được Nhà nước giao quyền sử dụng đất, có quyền lợi và '\n",
      " 'nghĩa vụ đối với đất đai.\\n'\n",
      " '\\n'\n",
      " 'Theo Điều 3, Luật Đất đai năm 2024, \"người sử dụng đất\" bao gồm:\\n'\n",
      " '\\n'\n",
      " '* Cá nhân có quyền sử dụng đất;\\n'\n",
      " '* Tổ chức có quyền sử dụng đất;\\n'\n",
      " '* Hợp tác xã, hợp tác xã nông nghiệp, hợp tác xã dịch vụ;\\n'\n",
      " '* Đơn vị hành chính, đơn vị sự nghiệp;\\n'\n",
      " '* Doanh nghiệp, công ty;\\n'\n",
      " '* Tổ chức tín dụng;\\n'\n",
      " '* Tổ chức khác được Nhà nước giao quyền sử dụng đất.\\n'\n",
      " '\\n'\n",
      " 'Tuy nhiên, theo Điều 40, Văn bản số 96/2024/NĐ-CP, \"người sử dụng đất\" cũng '\n",
      " 'bao gồm các đối tượng sau:\\n'\n",
      " '\\n'\n",
      " '* Các tổ chức, cá nhân đã được Nhà nước giao quyền sử dụng đất;\\n'\n",
      " '* Các tổ chức, cá nhân đã được Nhà nước giao quyền sở hữu đất đai;\\n'\n",
      " '* Các tổ chức, cá nhân đã được Nhà nước giao quyền quản lý, sử dụng đất '\n",
      " 'đai.\\n'\n",
      " '\\n'\n",
      " 'Theo Luật Đất đai năm 2024, người sử dụng đất có quyền và nghĩa vụ sau:\\n'\n",
      " '\\n'\n",
      " '* Quyền: được sử dụng đất, được quyền lợi về đất đai, được chuyển đổi, '\n",
      " 'chuyển nhượng, tặng cho quyền sử dụng đất, được thế chấp, được ủy quyền sử '\n",
      " 'dụng đất.\\n'\n",
      " '* Nghĩa vụ: phải thực hiện các nghĩa vụ về đất đai, phải nộp thuế về đất '\n",
      " 'đai, phải thực hiện các nghĩa vụ về môi trường, phải thực hiện các nghĩa vụ '\n",
      " 'về an ninh, trật tự.\\n'\n",
      " '\\n'\n",
      " 'Tóm lại, \"người sử dụng đất\" là các tổ chức, cá nhân được Nhà nước giao '\n",
      " 'quyền sử dụng đất, có quyền lợi và nghĩa vụ đối với đất đai, và phải thực '\n",
      " 'hiện các nghĩa vụ về đất đai, môi trường, an ninh, trật tự.')\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "\n",
    "        if key == \"filter_question\" and value == \"yes\":\n",
    "            pprint(\"xin loi toi khong the tra loi cau hoi nay\")\n",
    "            break\n",
    "\n",
    "    if \"generation\" in value:\n",
    "        pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_libs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
