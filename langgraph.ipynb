{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & call llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linhbk/Documents/python projects/NCKH_2024/RagAgent/agent_libs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_model = FastEmbedEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    cache_dir=\"./embedding_cache\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "llm = ChatGroq(model_name='Llama3-8b-8192', api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Chunking text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/vectorstore.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_with_metadata = json.load(f)\n",
    "\n",
    "doc_splits = [\n",
    "    Document(\n",
    "        page_content=chunk[\"text\"],\n",
    "        metadata={\n",
    "            \"chapter\": chunk[\"metadata\"][\"chapter\"],\n",
    "            \"title\": chunk[\"metadata\"][\"title\"],\n",
    "            \"date\": chunk[\"metadata\"][\"date\"]\n",
    "        }\n",
    "    ) for chunk in chunks_with_metadata\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2607"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_count = len(doc_splits)\n",
    "doc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save vector db in persist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist_directory = './real_estate_db/luat_dat_dai'\n",
    "persist_directory = './real_estate_db/vectorstore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create db\n",
    "# vectorstore_created = Chroma.from_documents(documents=doc_splits,\n",
    "#                                     embedding=embed_model,\n",
    "#                                     persist_directory=persist_directory,\n",
    "#                                     collection_name=\"vectorstore\")\n",
    "# vectorstore_created.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/64gffy7j1_79tlsdxkhtcjg00000gp/T/ipykernel_14913/1442968809.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embed_model, collection_name=\"vectorstore\")\n"
     ]
    }
   ],
   "source": [
    "# call from existed db\n",
    "vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embed_model, collection_name=\"vectorstore\")\n",
    "# vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stored documents: 2607\n",
      "Files in persistence directory: ['1aead4fb-bcb3-496d-86d1-dda9b04741f6', 'chroma.sqlite3']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stored documents:\", vectorstore._collection.count())\n",
    "# print(\"First document:\", doc_splits[-1].page_content if doc_splits else \"No documents found!\")\n",
    "print(\"Files in persistence directory:\", os.listdir(persist_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available collections: ['vectorstore']\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "client = PersistentClient(path=persist_directory)\n",
    "collections = client.list_collections()\n",
    "print(\"Available collections:\", collections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_lambda = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.schema import Document\n",
    "# from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# # convert chunks to document\n",
    "# def format_text_chunks(text_chunks):\n",
    "#     return [Document(page_content=chunk) for chunk in text_chunks]\n",
    "\n",
    "# retriever_lambda = RunnableLambda(lambda x: format_text_chunks(retriever.get_relevant_documents(x[\"question\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'vectorstore'}\n",
      "The time required to generate response by Router Chain in seconds:150.690767288208\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on real estate laws in Vietnam. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "question_router = router_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "question = \"“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\"\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by Router Chain in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cc/64gffy7j1_79tlsdxkhtcjg00000gp/T/ipykernel_14913/2309398310.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever_lambda = RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"question\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theo quy định của Luật Đất đai năm 2024, \"Người sử dụng đất\" được quy định tại Điều 3 của Luật này. Tuy nhiên, không tìm thấy quy định tại Điều 3 về định nghĩa \"Người sử dụng đất\". Vì vậy, chúng ta cần tìm kiếm tại các điều khác.\n",
      "\n",
      "Tại Điều 40 của Nghị định số 96/2024/NĐ-CP, có quy định về \"Người sử dụng đất\" như sau:\n",
      "\n",
      "\"Người sử dụng đất là chủ sở hữu, người được giao đất, người được thuê đất, người được phép sử dụng đất theo quy định của pháp luật về đất đai\"\n",
      "\n",
      "Theo quy định trên, \"Người sử dụng đất\" bao gồm:\n",
      "\n",
      "* Chủ sở hữu đất\n",
      "* Người được giao đất\n",
      "* Người được thuê đất\n",
      "* Người được phép sử dụng đất theo quy định của pháp luật về đất đai\n",
      "\n",
      "Vậy, người sử dụng đất là các cá nhân, tổ chức được giao, thuê, hoặc được phép sử dụng đất đai theo quy định của pháp luật về đất đai.\n",
      "\n",
      "References:\n",
      "- Luật Đất đai năm 2024\n",
      "- Nghị định số 96/2024/NĐ-CP\n",
      "\n",
      "Note: Although the exact definition of \"Người sử dụng đất\" is not found in the Law on Land 2024, the definition can be inferred from the provisions of Article 40 of Decree No. 96/2024/NĐ-CP.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just refuse answer in polite and friendly. \n",
    "    Answer question in detailed, make sure references vietnamese's law that prove for your answer. \n",
    "    For example:\n",
    "    Question: Phạm vi điều chỉnh và đối tượng áp dụng Luật Đất đai năm 2024 là gì?\n",
    "    Answer: \n",
    "    Điều 1. Phạm vi điều chỉnh\n",
    "    Luật này quy định về chế độ sở hữu đất đai, quyền hạn và trách nhiệm của Nhà nước đại diện chủ sở hữu toàn dân về đất đai và thống nhất quản lý về đất đai, chế độ quản lý và sử dụng đất đai, quyền và nghĩa vụ của công dân, người sử dụng đất đối với đất đai thuộc lãnh thổ của nước Cộng hòa xã hội chủ nghĩa Việt Nam.\n",
    "    Điều 2. Đối tượng áp dụng\n",
    "    1. Cơ quan nhà nước thực hiện quyền hạn và trách nhiệm đại diện chủ sở hữu toàn dân về đất đai, thực hiện nhiệm vụ thống nhất quản lý nhà nước về đất đai.\n",
    "    2. Người sử dụng đất.\n",
    "    3. Các đối tượng khác có liên quan đến việc quản lý, sử dụng đất đai.'\n",
    "    Answer in professional in vietnamese.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "start = time.time()\n",
    "rag_chain = (\n",
    "    {\"question\": lambda x: x[\"question\"], \"context\": retriever_lambda}\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# test\n",
    "# question = \"luật nhà ở 2024\"\n",
    "response = rag_chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc 1 content: Điều 28.Nhận quyền sử dụng đất\n",
      "1\n",
      "retriever 1 grade: {'score': 'no'}\n",
      "doc 2 content: - Những hạn chế về quyền sử dụng đất (nếu có): ..........................................................\n",
      "2\n",
      "retriever 2 grade: {'score': 'no'}\n",
      "doc 3 content: quyền sử dụng đất thì không cần mô tả thông tin này)\n",
      "- Tiến độ thực hiện: .....................................................................................................\n",
      "- Các nội dung khác: ...................................................................................................\n",
      "điều 2\n",
      "retriever 3 grade: {'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "retrieval_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination. \\n\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "start = time.time()\n",
    "retrieval_grader = retrieval_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "docs = retriever.invoke(question)\n",
    "end = time.time()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    doc_txt = doc.page_content\n",
    "    print(f\"doc {i + 1} content: {doc_txt}\")\n",
    "    doc_grader = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "    print(f\"retriever {i + 1} grade: {doc_grader}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the generation chain in seconds:0.3308720588684082\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "hallucination_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "start = time.time()\n",
    "hallucination_grader = hallucination_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "hallucination_grader_response = hallucination_grader.invoke({\"documents\": docs, \"generation\": response})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the generation chain in seconds:{end - start}\")\n",
    "print(hallucination_grader_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANswer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time required to generate response by the answer grader in seconds:0.32360291481018066\n",
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "answer_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "start = time.time()\n",
    "answer_grader = answer_grader_prompt | llm | JsonOutputParser()\n",
    "\n",
    "# test\n",
    "answer_grader_response = answer_grader.invoke({\"question\": question,\"generation\": response})\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the answer grader in seconds:{end - start}\")\n",
    "print(answer_grader_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Websearch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_api_key = os.environ['TAVILY_API_KEY']\n",
    "web_search_tool = TavilySearchResults(k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single test web_search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Nhìn lại thị trường bất động sản năm 2024 - Báo Kinh tế đô thị', 'url': 'https://kinhtedothi.vn/nhin-lai-thi-truong-bat-dong-san-nam-2024.html', 'content': 'Tính chung cả năm 2024, toàn thị trường ghi nhận khoảng gần 81.000 sản phẩm chào bán, tăng hơn 40% so với năm 2023. Trong đó, có 65,376 sản phẩ', 'score': 0.826278}, {'title': 'Năm 2024, nguồn cung bất động sản tăng trưởng mạnh', 'url': 'https://baochinhphu.vn/nam-2024-nguon-cung-bat-dong-san-tang-truong-manh-10224123109473222.htm', 'content': '(Chinhphu.vn) - Theo Hội Môi giới bất động sản Việt Nam (VARS), tính chung cả năm 2024, toàn thị trường ghi nhận khoảng gần 81 nghìn sản phẩm bất động sản (BĐS) chào bán, tăng hơn 40% so với năm 2023. Tại thời điểm cuối năm 2024, thị trường BĐS ghi nhận khoảng 56 nghìn sản phẩm chào bán trên thị trường sơ cấp, tương đương với thời điểm cuối năm 2023 do nhiều dự án \"giải phóng\" được lượng lớn hàng tồn trong bối cảnh thị trường phục hồi. Giao dịch thấp tầng cũng cải thiện mạnh trong bối cảnh thị trường phục hồi, tỷ lệ hấp thụ các dự án mở bán mới ở mức rất tốt, ước đạt gần 65%, tương đương với gần 9 nghìn giao dịch.', 'score': 0.81524754}, {'title': 'TỔNG HỢP THỊ TRƯỜNG BẤT ĐỘNG SẢN 2024 - HƯỚNG TỚI 2025', 'url': 'https://www.youtube.com/watch?v=cavyT74iC6s', 'content': '... bất động sản đất nền cũng tăng mạnh so với cuối năm 2023. Vậy, hay cùng nhìn lại các số liệu của thị trường bất động sản 2024 và hướng tới', 'score': 0.6929958}, {'title': 'Thị trường bất động sản đã “khép lại” năm 2024 với các kết quả ...', 'url': 'https://thoibaotaichinhvietnam.vn/thi-truong-bat-dong-san-da-khep-lai-nam-2024-voi-cac-ket-qua-phuc-hoi-tich-cuc-167692.html', 'content': '(TBTCO) - Theo đánh giá của Hội môi giới Bất động sản (VARS), thị trường bất động sản Việt Nam đã “khép lại” năm 2024 với các kết quả phục hồi tích cực nhờ các bước tiến lớn trong việc hoàn thiện hành lang pháp lý, với các thông tin ngày càng minh bạch, rõ ràng cho mọi thành phần tham gia. (TBTCO) - Năm 2025 được kỳ vọng là giai đoạn tăng trưởng mạnh của ngành bất động sản khu công nghiệp, hưởng lợi từ xu hướng \"Trung Quốc +1\" và dòng vốn FDI tiếp tục đổ vào Việt Nam. Giá thuê và diện tích hấp thụ ròng được dự báo tăng nhờ chính sách thương mại mới của Mỹ, cùng với sự cải thiện hạ tầng và tháo gỡ các vấn đề pháp lý.', 'score': 0.68496037}, {'title': 'Thị trường bất động sản năm 2024: Nhiều tiền đề quan trọng, tạo ...', 'url': 'https://vneconomy.vn/thi-truong-bat-dong-san-nam-2024nhieu-tien-de-quan-trong-tao-nen-cho-chu-ky-phat-trien-moi.htm', 'content': 'cũng như các khó khăn, vướng mắc của các dự án bất động sản, Chính phủ, Thủ tướng Chính phủ đã ban hành hàng loạt các chính sách, nhiệm vụ, giải pháp đồng bộ để tháo gỡ khó khăn cho thị trường bất động sản; Tổ công tác (thành lập theo Quyết định số 1435/QĐ-TTg ngày 17/11/2022 của Thủ tướng Chính phủ) cũng đã tiếp nhận, xử lý có hiệu quả các kiến nghị của địa phương, doanh nghiệp; cùng với đó, trong những tháng cuối năm, việc lãi suất ngân hàng cho vay mua bất động sản được điều chỉnh theo xu hướng giảm, thị trường bắt đầu có chuyển biến tích cực, lượng tìm kiếm giao dịch các phân khúc đất nền, chung cư...', 'score': 0.6227582}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.tools import TavilySearchResults\n",
    "\n",
    "def search_web(query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Searches the web using Tavily API for the given query.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The search query.\n",
    "    - k (int): Number of search results to return (default is 3).\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of search result snippets.\n",
    "    \"\"\"\n",
    "    tavily_api_key = os.environ['TAVILY_API_KEY']\n",
    "    web_search_tool = TavilySearchResults(k=k)\n",
    "    \n",
    "    try:\n",
    "        results = web_search_tool.run(query)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error while searching: {e}\")\n",
    "        return []\n",
    "\n",
    "query = \"TÌnh hình bất đọngo sản 2024\"\n",
    "search_results = search_web(query)\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraphh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str]\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "#\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    iterations = state.get(\"iterations\", 0) + 1\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation, \"iterations\": iterations}\n",
    "#\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # We do not include the document in filtered_docs\n",
    "            # We set a flag to indicate that we want to run web search\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "#\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    iterations = state.get(\"iterations\", 0) + 1\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.run({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents is not None:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question, \"iterations\": iterations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        print(\"---ROUTE QUESTION TO RAG---\")\n",
    "        return \"vectorstore\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "    iterations = state.get(\"iterations\", 0)\n",
    "    \n",
    "    if iterations >= 10:\n",
    "        print(\"GETTING MAX ATTEMPTS\")\n",
    "        return \"end\"\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x117c06bd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) # generatae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry & End points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x117c06bd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "        \"end\": END\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTE QUESTION---\n",
      "“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\n",
      "{'datasource': 'vectorstore'}\n",
      "vectorstore\n",
      "---ROUTE QUESTION TO RAG---\n",
      "---RETRIEVE---\n",
      "'Finished running: retrieve:'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, INCLUDE WEB SEARCH---\n",
      "'Finished running: grade_documents:'\n",
      "---WEB SEARCH---\n",
      "'Finished running: websearch:'\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "'Finished running: generate:'\n",
      "('Theo quy định của Luật Đất đai năm 2024, \"người sử dụng đất\" được hiểu là '\n",
      " 'những người có quyền sử dụng đất, bao gồm:\\n'\n",
      " '\\n'\n",
      " '* Chủ tịch Ủy ban nhân dân các cấp;\\n'\n",
      " '* Hội đồng nhân dân các cấp;\\n'\n",
      " '* Các cơ quan nhà nước;\\n'\n",
      " '* Tổ chức, cá nhân được Nhà nước cấp giấy chứng nhận quyền sử dụng đất;\\n'\n",
      " '* Những người được Nhà nước giao đất, cho thuê đất;\\n'\n",
      " '* Những người được thừa kế quyền sử dụng đất;\\n'\n",
      " '* Những người được mua, được tặng, được đoạt quyền sử dụng đất.\\n'\n",
      " '\\n'\n",
      " 'Điều 28 của Luật Đất đai năm 2024 quy định: \"Nhận quyền sử dụng đất\" là việc '\n",
      " 'Nhà nước giao đất, cho thuê đất, cấp quyền sử dụng đất cho người sử dụng '\n",
      " 'đất.\\n'\n",
      " '\\n'\n",
      " 'Điều 40 của Nghị định số 96/2024/NĐ-CP ngày 24/07/2024 quy định: \"Quyền sử '\n",
      " 'dụng đất\" bao gồm quyền sử dụng đất, quyền quản lý đất, quyền chuyển đổi, '\n",
      " 'chuyển nhượng, cho thuê, thừa kế, tặng cho quyền sử dụng đất.\\n'\n",
      " '\\n'\n",
      " 'Theo các quy định trên, người sử dụng đất là những người có quyền sử dụng '\n",
      " 'đất, bao gồm cả chủ thể có quyền sử dụng đất và người được Nhà nước giao '\n",
      " 'đất, cho thuê đất, cấp quyền sử dụng đất.\\n'\n",
      " '\\n'\n",
      " 'References:\\n'\n",
      " '- Luật Đất đai năm 2024, Điều 28\\n'\n",
      " '- Nghị định số 96/2024/NĐ-CP ngày 24/07/2024, Điều 40')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"“Người sử dụng đất” được hiểu như thế nào theo quy định của Luật Đất đai năm 2024?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}:\")\n",
    "    # if \"generation\" in value:\n",
    "    #     pprint(value[\"generation\"])\n",
    "    # else:\n",
    "    #     pprint(\"Hiện mình chưa có thông tin về câu hỏi của bạn. Bạn có thể thử lại với câu hỏi khác không?\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_libs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
